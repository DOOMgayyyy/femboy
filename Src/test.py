import requests
from bs4 import BeautifulSoup, Tag
from urllib.parse import urljoin
import os
import json
import time
import re

class ProductParser:
    def __init__(self):
        self.base_url = 'https://gosapteka18.ru'
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
            'X-Requested-With': 'XMLHttpRequest'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.price_regexes = [
            re.compile(r'product-card__price-value[^>]*>([\d\s,]+)'),
            re.compile(r'"price"\s*:\s*"(\d+\.?\d*)"'),
            re.compile(r'itemprop="price"[^>]+content="(\d+\.?\d*)"')
        ]

    def fetch_html(self, url: str) -> str | None:
        try:
            time.sleep(1)
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            return response.text
        except requests.exceptions.RequestException as e:
            print(f"üö´ –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}: {e}")
            return None

    def parse_product(self, product_url: str):
        print(f"‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–∞: {product_url}")
        html = self.fetch_html(product_url)
        if not html:
            return None
            
        soup = BeautifulSoup(html, 'html.parser')
        
        # –ü–æ–ª—É—á–∞–µ–º ID —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Ü–µ–Ω—ã
        product_id = self._get_product_id(soup)
        
        product_data = {
            'url': product_url,
            'title': self._get_title(soup),
            'price': self._get_price(html),
            'manufacturer': self._get_manufacturer(soup),
            'description': self._get_description(soup),
            'image_url': self._get_image(soup)
        }
        
        self.save_results(product_data)
        return product_data
    
    def _get_product_id(self, soup) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ID —Ç–æ–≤–∞—Ä–∞ –∏–∑ HTML"""
        product_id_tag = soup.select_one('div.product-card[data-product-id]')
        return product_id_tag['data-product-id'] if product_id_tag else None
    
    def _get_price(self, html):
        for regex in self.price_regexes:
            if match := regex.search(html):
                try:
                    price_str = match.group(1).replace(' ', '').replace(',', '.')
                    return float(price_str)
                except (ValueError, TypeError):
                    continue
        return None

    def _clean_price(self, price_text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ü–µ–Ω—É –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        if price_text is None:
            return "0.00"
        
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ç–æ—á–∫–∏ –∏ –∑–∞–ø—è—Ç–æ–π
        cleaned = re.sub(r'[^\d,.]', '', price_text)
        cleaned = cleaned.replace(',', '.').strip()
        
        if cleaned:
            try:
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ü–µ–Ω—É —Å –¥–≤—É–º—è –∑–Ω–∞–∫–∞–º–∏ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π
                return f"{float(cleaned):.2f}"
            except ValueError:
                return "0.00"
        return "0.00"

    def _get_title(self, soup) -> str:
        title_tag = soup.select_one('h1.title.headline-main__title.product-card__title')
        return title_tag.get_text(strip=True) if title_tag else ''

    def _get_description(self, soup) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä—è {–∑–∞–≥–æ–ª–æ–≤–æ–∫: —Ç–µ–∫—Å—Ç}"""
        description_block = soup.select_one('div.product-card__description')
        if not description_block:
            return {}
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –Ω–∏–º–∏ –¥–∞–Ω–Ω—ã–µ
        sections = {}
        current_header = None
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –¥–æ—á–µ—Ä–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –±–ª–æ–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è
        for child in description_block.children:
            if isinstance(child, Tag):
                # –ù–∞—à–ª–∏ –Ω–æ–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                if child.name == 'h4':
                    current_header = child.get_text(strip=True)
                    sections[current_header] = []
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
                elif current_header:
                    # –î–ª—è —Ç–µ–≥–æ–≤ <p> –∏–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
                    if child.name == 'p':
                        text = child.get_text(strip=True)
                        if text:
                            sections[current_header].append(text)
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥—Ä—É–≥–∏–µ —Ç–µ–≥–∏ (div, span –∏ —Ç.–¥.)
                    else:
                        text = child.get_text(" ", strip=True)
                        if text:
                            sections[current_header].append(text)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ø–∏—Å–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∏
        for header in sections:
            sections[header] = "\n".join(sections[header])
        
        return sections

    def _get_manufacturer(self, soup) -> str:
        manufacturer_tag = soup.select_one('span.product-card__brand-value')
        return manufacturer_tag.get_text(strip=True) if manufacturer_tag else ''

    def _get_image(self, soup) -> str:
        image_tag = soup.select_one('img.product-card__picture-view-img')
        if image_tag and 'src' in image_tag.attrs:
            return urljoin(self.base_url, image_tag['src'])
        return ''

    def save_results(self, product_data: dict):
        title = product_data.get('title', 'unknown_product')
        slug = re.sub(r'[^\w]+', '_', title)[:100].strip('_')
        filename = f"{slug}.json"
        
        os.makedirs('product_data', exist_ok=True)
        filepath = os.path.join('product_data', filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(product_data, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filepath}")
        return filepath


if __name__ == "__main__":
    product_url = "https://gosapteka18.ru/catalog/velledien_2_5mg_tab_28.html"
    
    parser = ProductParser()
    product_data = parser.parse_product(product_url)
    
    if product_data:
        print("\n‚úÖ –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ:")
        print(f"–°—Å—ã–ª–∫–∞: {product_url}")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Ç–æ–≤–∞—Ä")